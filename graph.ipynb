{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import rdkit\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch_gometric.datasets import MoleculeNet\n",
    "\n",
    "#import os\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.mm(x, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        return output\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_nodes, num_features, num_edge_types, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_features = num_features\n",
    "        self.num_edge_types = num_edge_types\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Define weight matrices for each edge type\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(num_edge_types, num_features, hidden_size))\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "\n",
    "        # Define graph convolutional layers for each edge type\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        for r in range(num_edge_types):\n",
    "            self.gcn_layers.append(GraphConvolution(hidden_size, hidden_size))\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # Compute separate message vectors for each edge type\n",
    "        outputs = []\n",
    "        for r in range(self.num_edge_types):\n",
    "            weight_r = self.weights[r]\n",
    "            message_r = torch.mm(x, weight_r)\n",
    "            adj_r = adj[r]\n",
    "            output_r = self.gcn_layers[r](message_r, adj_r)\n",
    "            outputs.append(output_r)\n",
    "\n",
    "        # Aggregate message vectors across all incoming edges\n",
    "        output = torch.sum(torch.stack(outputs), dim=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 64]) torch.Size([100, 64])\n",
      "torch.Size([150, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.mm(x, self.weight)\n",
    "        output = torch.mm(adj, support)\n",
    "        return output\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_features, num_edge_types, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_features = num_features\n",
    "        self.num_edge_types = num_edge_types\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Define weight matrices for user and item nodes\n",
    "        self.user_weights = nn.Parameter(torch.FloatTensor(num_features, hidden_size))\n",
    "        nn.init.xavier_uniform_(self.user_weights)\n",
    "        self.item_weights = nn.Parameter(torch.FloatTensor(num_features, hidden_size))\n",
    "        nn.init.xavier_uniform_(self.item_weights)\n",
    "\n",
    "        # Define graph convolutional layers for each edge type\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        for r in range(num_edge_types):\n",
    "            self.gcn_layers.append(GraphConvolution(hidden_size, hidden_size))\n",
    "\n",
    "    def forward(self, user_inputs, item_inputs, adj):\n",
    "        # Compute separate message vectors for each edge type\n",
    "        user_messages = []\n",
    "        item_messages = []\n",
    "        for r in range(self.num_edge_types):\n",
    "            user_weight_r = self.user_weights\n",
    "            item_weight_r = self.item_weights\n",
    "            user_message_r = torch.mm(user_inputs, user_weight_r)\n",
    "            item_message_r = torch.mm(item_inputs, item_weight_r)\n",
    "            adj_r = adj[r]\n",
    "            user_output_r = self.gcn_layers[r](user_message_r, adj_r)\n",
    "            item_output_r = self.gcn_layers[r](item_message_r, adj_r.t())\n",
    "            user_messages.append(user_output_r)\n",
    "            item_messages.append(item_output_r)\n",
    "\n",
    "        # Aggregate message vectors across all incoming edges\n",
    "        user_output = torch.sum(torch.stack(user_messages), dim=0)\n",
    "        item_output = torch.sum(torch.stack(item_messages), dim=0)\n",
    "        print(user_output.shape, item_output.shape)\n",
    "        # Concatenate user and item output vectors\n",
    "        output = torch.cat([user_output, item_output], dim=0)\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "num_users = 100\n",
    "num_items = 50\n",
    "num_features = 32\n",
    "num_edge_types = 3\n",
    "hidden_size = 64\n",
    "\n",
    "user_inputs = torch.randn(num_users, num_features)\n",
    "item_inputs = torch.randn(num_items, num_features)\n",
    "adj = [torch.randn(num_items, num_users) for _ in range(num_edge_types)]\n",
    "\n",
    "encoder = Encoder(num_users, num_items, num_features, num_edge_types, hidden_size)\n",
    "output = encoder(user_inputs, item_inputs, adj)\n",
    "\n",
    "print(output.shape)  # should be [num_users + num_items, hidden_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Define GNN model\n",
    "class RatingPredictionGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(RatingPredictionGNN, self).__init__()\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(GCNConv(input_dim, hidden_dim))\n",
    "        for i in range(num_layers-1):\n",
    "            self.conv_layers.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        self.fc_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.conv_layers:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define dataset\n",
    "X = torch.randn(N, D)\n",
    "M = torch.randn(N, M)\n",
    "edge_index = ...  # construct edge_index for the bipartite graph\n",
    "y = torch.randn(N, M)\n",
    "\n",
    "# Prepare embeddings\n",
    "U = torch.randn(Nu, E)\n",
    "V = torch.randn(Nv, E)\n",
    "\n",
    "# Concatenate embeddings to input features\n",
    "U = U.unsqueeze(1).expand(Nu, N, E)\n",
    "V = V.unsqueeze(0).expand(N, Nv, E)\n",
    "X = torch.cat([X, U, V], dim=2)\n",
    "\n",
    "# Construct the adjacency matrices Mr from the original rating matrix M\n",
    "Mr_list = []\n",
    "for rating_type in rating_types:\n",
    "    Mr = torch.zeros(N, N)\n",
    "    mask = (M == rating_type)\n",
    "    Mr[mask] = 1\n",
    "    Mr_list.append(Mr)\n",
    "\n",
    "# Train the GNN\n",
    "model = RatingPredictionGNN(input_dim=X.shape[2], hidden_dim=32, num_layers=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X, edge_index)\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: {:03d}, Loss: {:.4f}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESOL(1128)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the ESOL dataset\n",
    "data = MoleculeNet(root=\".\", name=\"ESOL\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load('./esol/processed/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the dataset\n",
    "print(\"Dataset type: \", type(data))\n",
    "print(\"Dataset features: \", data.num_features)\n",
    "print(\"Dataset target: \", data.num_classes)\n",
    "print(\"Dataset length: \", data.len)\n",
    "print(\"Dataset sample: \", data[0])\n",
    "print(\"Sample  nodes: \", data[0].num_nodes)\n",
    "print(\"Sample  edges: \", data[0].num_edges)\n",
    "\n",
    "# edge_index = graph connections\n",
    "# smiles = molecule with its atoms\n",
    "# x = node features (32 nodes have each 9 features)\n",
    "# y = labels (dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].edge_index.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x2928ad24350>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "molecule = Chem.MolFromSmiles(data[0][\"smiles\"])\n",
    "molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  13249\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "embedding_size = 64\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
    "\n",
    "        # Output layer\n",
    "        self.out = Linear(embedding_size*2, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv3(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "          \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.out(hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "model = GCN()\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESOL(1128)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap data in a data loader\n",
    "data_size = len(data)\n",
    "NUM_GRAPHS_PER_BATCH = 64\n",
    "loader = DataLoader(data[:int(data_size * 0.8)], \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6068\\2281047059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Godwin\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Godwin\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Godwin\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Godwin\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Handle `CustomType` automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \"\"\"\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Godwin\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 1]) torch.Size([50, 5, 50])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (50) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11984\\2450586410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Compute the predicted rating probabilities for the batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mrating_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# Print the shape of the output tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Godwin\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11984\\2450586410.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, user_indices, item_indices)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mitem_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mbilinear_products\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mbilinear_products\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbilinear_products\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mrating_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbilinear_products\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rating_levels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (50) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class BilinearDecoder(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_rating_levels, hidden_dim):\n",
    "        super(BilinearDecoder, self).__init__()\n",
    "        self.Q = nn.Parameter(torch.randn(hidden_dim, num_rating_levels, hidden_dim))\n",
    "        self.user_embedding = nn.Embedding(num_users, hidden_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, hidden_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.num_rating_levels = num_rating_levels\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        print(user_embeddings.unsqueeze(2).shape, self.Q.shape)\n",
    "        bilinear_products = torch.matmul(user_embeddings.unsqueeze(2), self.Q)\n",
    "        bilinear_products = torch.matmul(bilinear_products, item_embeddings.unsqueeze(1))\n",
    "        rating_probs = self.softmax(bilinear_products.view(-1, self.num_rating_levels))\n",
    "        return rating_probs\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "num_users = 100\n",
    "num_items = 200\n",
    "num_rating_levels = 5\n",
    "hidden_dim = 50\n",
    "\n",
    "# Create a batch of user-item pairs\n",
    "batch_size = 32\n",
    "user_indices = torch.randint(num_users, size=(batch_size,))\n",
    "item_indices = torch.randint(num_items, size=(batch_size,))\n",
    "\n",
    "# Create an instance of the bilinear decoder\n",
    "decoder = BilinearDecoder(num_users, num_items, num_rating_levels, hidden_dim)\n",
    "\n",
    "# Compute the predicted rating probabilities for the batch\n",
    "rating_probs = decoder(user_indices, item_indices)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(rating_probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Root mean squared error\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0007)  \n",
    "\n",
    "# Use GPU for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Wrap data in a data loader\n",
    "data_size = len(data)\n",
    "NUM_GRAPHS_PER_BATCH = 64\n",
    "loader = DataLoader(data[:int(data_size * 0.8)], \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "test_loader = DataLoader(data[int(data_size * 0.8):], \n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "def train(data):\n",
    "    # Enumerate over the data\n",
    "    for batch in loader:\n",
    "      # Use GPU\n",
    "      batch.to(device)  \n",
    "      # Reset gradients\n",
    "      optimizer.zero_grad() \n",
    "      # Passing the node features and the connection info\n",
    "      pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
    "      # Calculating the loss and gradients\n",
    "      loss = loss_fn(pred, batch.y)     \n",
    "      loss.backward()  \n",
    "      # Update using the gradients\n",
    "      optimizer.step()   \n",
    "    return loss, embedding\n",
    "\n",
    "def save_checkpoint(state, filename = 'checkpoint.pth.tar'):\n",
    "    print('Saving checkpoint ==>>')\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint_path):\n",
    "    print('Loading Checkpoing ==>>')\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "\n",
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "for epoch in range(2000):\n",
    "    loss, h = train(data)\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "      checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "      save_checkpoint(checkpoint)\n",
    "      print(f\"Epoch {epoch} | Train Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Visualize learning (training loss)\n",
    "import seaborn as sns\n",
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses] \n",
    "loss_indices = [i for i,l in enumerate(losses_float)] \n",
    "plt = sns.lineplot(loss_indices, losses_float)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path):\n",
    "    print('Loading Checkpoing ==>>')\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoing ==>>\n",
      "2323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='y_real', ylabel='y_pred'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "load_checkpoint('checkpoint.pth.tar')\n",
    "# Analyze the results for one batch\n",
    "#model = torch\n",
    "test_batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    test_batch.to(device)\n",
    "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch) \n",
    "    df = pd.DataFrame()\n",
    "    df[\"y_real\"] = test_batch.y.tolist()\n",
    "    df[\"y_pred\"] = pred.tolist()\n",
    "df[\"y_real\"] = df[\"y_real\"].apply(lambda row: row[0])\n",
    "df[\"y_pred\"] = df[\"y_pred\"].apply(lambda row: row[0])\n",
    "print(2323)\n",
    "plt = sns.scatterplot(data=df, x=\"y_real\", y=\"y_pred\")\n",
    "plt.set(xlim=(-7, 2))\n",
    "plt.set(ylim=(-7, 2))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GATConv(64, 64, heads=3)\n",
      "  (conv2): GATConv(64, 64, heads=2)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  26177\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, GATConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "embedding_size = 64\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
    "        self.conv1 = GATConv(embedding_size, embedding_size, heads=3, concat=False)\n",
    "        self.conv2 = GATConv(embedding_size, embedding_size, heads=2, concat=False)\n",
    "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
    "\n",
    "        # Output layer\n",
    "        self.out = Linear(embedding_size*2, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv3(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "          \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.out(hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "model = GCN()\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Saving checkpoint ==>>\n",
      "Epoch 0 | Train Loss 7.432424545288086\n",
      "Saving checkpoint ==>>\n",
      "Epoch 100 | Train Loss 1.0947860479354858\n",
      "Saving checkpoint ==>>\n",
      "Epoch 200 | Train Loss 0.5690834522247314\n",
      "Saving checkpoint ==>>\n",
      "Epoch 300 | Train Loss 0.36598876118659973\n",
      "Saving checkpoint ==>>\n",
      "Epoch 400 | Train Loss 0.3962383270263672\n",
      "Saving checkpoint ==>>\n",
      "Epoch 500 | Train Loss 0.3234870731830597\n",
      "Saving checkpoint ==>>\n",
      "Epoch 600 | Train Loss 0.7849053740501404\n",
      "Saving checkpoint ==>>\n",
      "Epoch 700 | Train Loss 0.2792257070541382\n",
      "Saving checkpoint ==>>\n",
      "Epoch 800 | Train Loss 0.4121960699558258\n",
      "Saving checkpoint ==>>\n",
      "Epoch 900 | Train Loss 0.026720764115452766\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1000 | Train Loss 0.0579131543636322\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1100 | Train Loss 0.3430059254169464\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1200 | Train Loss 0.07266966253519058\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1300 | Train Loss 0.12433604151010513\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1400 | Train Loss 0.020751895383000374\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1500 | Train Loss 0.02669484168291092\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1600 | Train Loss 0.03194199129939079\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1700 | Train Loss 0.026297638192772865\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1800 | Train Loss 0.03578464686870575\n",
      "Saving checkpoint ==>>\n",
      "Epoch 1900 | Train Loss 0.015447213314473629\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0007)  \n",
    "\n",
    "# Use GPU for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Wrap data in a data loader\n",
    "data_size = len(data)\n",
    "NUM_GRAPHS_PER_BATCH = 64\n",
    "loader = DataLoader(data[:int(data_size * 0.8)], \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "test_loader = DataLoader(data[int(data_size * 0.8):], \n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "def train(data):\n",
    "    # Enumerate over the data\n",
    "    for batch in loader:\n",
    "      # Use GPU\n",
    "      batch.to(device)  \n",
    "      # Reset gradients\n",
    "      optimizer.zero_grad() \n",
    "      # Passing the node features and the connection info\n",
    "      pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
    "      # Calculating the loss and gradients\n",
    "      loss = loss_fn(pred, batch.y)     \n",
    "      loss.backward()  \n",
    "      # Update using the gradients\n",
    "      optimizer.step()   \n",
    "    return loss, embedding\n",
    "\n",
    "\n",
    "print(\"Starting training...\")\n",
    "losses = []\n",
    "for epoch in range(2000):\n",
    "    loss, h = train(data)\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "      checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "      save_checkpoint(checkpoint)\n",
    "      print(f\"Epoch {epoch} | Train Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
