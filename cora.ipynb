{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "import scipy.sparse as sp #.coo_matrix\n",
    "import numpy as np\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Get some basic info about the dataset\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# There is only one graph in the dataset, use it as new data object\n",
    "data = dataset[0]  \n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(data)\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1433, 16)\n",
      "  (conv2): GCNConv(16, 16)\n",
      "  (out): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv #GATConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Initialize the layers\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.out = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Message Passing Layer (Transformation)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Second Message Passing Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Output layer \n",
    "        x = F.softmax(self.out(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 7])\n",
      "Epoch: 000, Loss: 1.9461\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = GCN(hidden_channels=16)\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "# Initialize Optimizer\n",
    "learning_rate = 0.01\n",
    "decay = 5e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=decay)\n",
    "# Define loss function (CrossEntropyLoss for Classification Problems with \n",
    "# probability distributions)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad() \n",
    "      # Use all data as input, because all nodes have node features\n",
    "      out = model(data.x, data.edge_index)  \n",
    "      print(out.shape)\n",
    "      # Only use nodes with labels available for loss calculation --> mask\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  \n",
    "      loss.backward() \n",
    "      optimizer.step()\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      # Use the class with highest probability.\n",
    "      pred = out.argmax(dim=1)  \n",
    "      # Check against ground-truth labels.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  \n",
    "      # Derive ratio of correct predictions.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  \n",
    "      return test_acc\n",
    "\n",
    "losses = []\n",
    "for epoch in range(0, 1001):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses] \n",
    "loss_indices = [i for i,l in enumerate(losses_float)] \n",
    "plt = sns.lineplot(loss_indices, losses_float)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "def plt2arr(fig):\n",
    "    rgb_str = fig.canvas.tostring_rgb()\n",
    "    (w,h) = fig.canvas.get_width_height()\n",
    "    rgba_arr = np.fromstring(rgb_str, dtype=np.uint8, sep='').reshape((w,h,-1))\n",
    "    return rgba_arr\n",
    "\n",
    "\n",
    "def visualize(h, color, epoch):\n",
    "    fig = plt.figure(figsize=(5,5), frameon=False)\n",
    "    fig.suptitle(f'Epoch = {epoch}')\n",
    "    # Fit TSNE with 2 components\n",
    "    z = TSNE(n_components=2).fit_transform(out.detach().cpu().numpy())\n",
    "\n",
    "    # Create scatterplot from embeddings\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.scatter(z[:, 0], \n",
    "                z[:, 1], \n",
    "                s=70, \n",
    "                c=color.detach().cpu().numpy(), \n",
    "                cmap=\"Set2\")\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Convert to numpy\n",
    "    return plt2arr(fig)\n",
    "\n",
    "\n",
    "# Reset the previously trained model weights\n",
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "     ------------------------------------ 388.3/388.3 kB 671.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting decorator<5.0,>=4.0.2\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from moviepy) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from moviepy) (2.28.1)\n",
      "Collecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from moviepy) (1.21.5)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from moviepy) (2.19.3)\n",
      "Collecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-win_amd64.whl (22.6 MB)\n",
      "     ---------------------------------------- 22.6/22.6 MB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\godwin\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.5)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py): started\n",
      "  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110728 sha256=1b2ccc702797809778e0ed9937444a425305c9ba1428e1adaf7600268abd49fc\n",
      "  Stored in directory: c:\\users\\godwin\\appdata\\local\\pip\\cache\\wheels\\29\\15\\e4\\4f790bec6acd51a00b67e8ee1394f0bc6e0135c315f8ff399a\n",
      "Successfully built moviepy\n",
      "Installing collected packages: imageio_ffmpeg, decorator, proglog, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 imageio_ffmpeg-0.4.8 moviepy-1.0.3 proglog-0.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore deprecation warnings here\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Train the model and save visualizations\n",
    "images = []\n",
    "for epoch in range(0, 2000):\n",
    "    loss = train()\n",
    "    if epoch % 50 == 0:\n",
    "      out = model(data.x, data.edge_index)\n",
    "      images.append(visualize(out, color=data.y, epoch=epoch))\n",
    "print(\"TSNE Visualization finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "fps = 1\n",
    "filename = \"/content/embeddings.gif\"\n",
    "clip = ImageSequenceClip(images, fps=fps)\n",
    "clip.write_gif(filename, fps=fps)\n",
    "\n",
    "from IPython.display import Image\n",
    "with open('/content/embeddings.gif','rb') as f:\n",
    "    display(Image(data=f.read(), format='png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
